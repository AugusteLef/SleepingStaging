{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 AML : Sleeping Staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/atroska/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/atroska/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.21.2)\n",
      "Requirement already satisfied: scipy>=0.17.1 in /home/atroska/.local/lib/python3.6/site-packages (from mne) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.16.1)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib:$HOME=/home/atroska\n",
      "DEBUG:matplotlib:CONFIGDIR=/home/atroska/.config/matplotlib\n",
      "DEBUG:matplotlib:matplotlib data path: /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data\n",
      "DEBUG:matplotlib:loaded rc file /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/matplotlibrc\n",
      "DEBUG:matplotlib:matplotlib version 3.0.2\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is linux\n",
      "DEBUG:matplotlib:loaded modules: ['builtins', 'sys', '_frozen_importlib', '_imp', '_warnings', '_thread', '_weakref', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'zipimport', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_weakrefset', '_bootlocale', '_locale', 'site', 'os', 'errno', 'stat', '_stat', 'posixpath', 'genericpath', 'os.path', '_collections_abc', '_sitebuiltins', 'sysconfig', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'types', 'functools', '_functools', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'weakref', 'collections.abc', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'google', 'mpl_toolkits', 'zope', 'sitecustomize', 'apport_python_hook', 'runpy', 'pkgutil', 'ipykernel', 'ipykernel._version', 'ipykernel.connect', '__future__', 'json', 'json.decoder', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'copyreg', 'json.scanner', '_json', 'json.encoder', 'subprocess', 'time', 'signal', '_posixsubprocess', 'select', 'selectors', 'math', 'threading', 'traceback', 'linecache', 'tokenize', 'token', 'IPython', 'IPython.core', 'IPython.core.getipython', 'IPython.core.release', 'IPython.core.application', 'atexit', 'copy', 'glob', 'fnmatch', 'logging', 'string', '_string', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'traitlets', 'traitlets.traitlets', 'inspect', 'ast', '_ast', 'dis', 'opcode', '_opcode', 'six', 'struct', '_struct', 'traitlets.utils', 'traitlets.utils.getargspec', 'traitlets.utils.importstring', 'ipython_genutils', 'ipython_genutils._version', 'ipython_genutils.py3compat', 'ipython_genutils.encoding', 'locale', 'platform', 'traitlets.utils.sentinel', 'traitlets.utils.bunch', 'traitlets._version', 'traitlets.config', 'traitlets.config.application', 'decorator', 'traitlets.config.configurable', 'traitlets.config.loader', 'argparse', 'textwrap', 'gettext', 'ipython_genutils.path', 'random', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'ipython_genutils.text', 'ipython_genutils.importstring', 'IPython.core.crashhandler', 'pprint', 'IPython.core.ultratb', 'pydoc', 'urllib', 'urllib.parse', 'IPython.core.debugger', 'bdb', 'IPython.utils', 'IPython.utils.PyColorize', 'IPython.utils.coloransi', 'IPython.utils.ipstruct', 'IPython.utils.colorable', 'pygments', 'pygments.util', 'IPython.utils.py3compat', 'IPython.utils.encoding', 'IPython.core.excolors', 'IPython.testing', 'IPython.testing.skipdoctest', 'pdb', 'cmd', 'code', 'codeop', 'IPython.core.display_trap', 'IPython.utils.path', 'IPython.utils.process', 'IPython.utils._process_posix', 'pexpect', 'pexpect.exceptions', 'pexpect.utils', 'pexpect.expect', 'pexpect.pty_spawn', 'pty', 'tty', 'termios', 'ptyprocess', 'ptyprocess.ptyprocess', 'fcntl', 'resource', 'ptyprocess.util', 'pexpect.spawnbase', 'pexpect.run', 'IPython.utils._process_common', 'shlex', 'IPython.utils.decorators', 'IPython.utils.data', 'IPython.utils.terminal', 'IPython.utils.sysinfo', 'IPython.utils._sysinfo', 'IPython.core.profiledir', 'IPython.paths', 'tempfile', 'IPython.utils.importstring', 'IPython.terminal', 'IPython.terminal.embed', 'IPython.core.compilerop', 'IPython.core.magic_arguments', 'IPython.core.error', 'IPython.utils.text', 'pathlib', 'ntpath', 'IPython.core.magic', 'getopt', 'IPython.core.oinspect', 'IPython.core.page', 'IPython.core.display', 'binascii', 'mimetypes', 'IPython.lib', 'IPython.lib.security', 'getpass', 'IPython.lib.pretty', 'datetime', '_datetime', 'IPython.utils.openpy', 'IPython.utils.dir2', 'IPython.utils.wildcard', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.plugin', 'pygments.lexers.python', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.token', 'pygments.regexopt', 'pygments.unistring', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'IPython.core.inputtransformer2', 'typing', 'typing.io', 'typing.re', 'IPython.core.interactiveshell', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'concurrent.futures.process', 'queue', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'pickle', '_compat_pickle', '_pickle', 'socket', '_socket', 'array', '__mp_main__', 'multiprocessing.connection', '_multiprocessing', 'multiprocessing.util', 'concurrent.futures.thread', 'asyncio.compat', 'asyncio.coroutines', 'asyncio.constants', 'asyncio.events', 'asyncio.base_futures', 'asyncio.log', 'asyncio.futures', 'asyncio.base_tasks', '_asyncio', 'asyncio.tasks', 'asyncio.locks', 'asyncio.protocols', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.transports', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'ssl', 'ipaddress', '_ssl', 'base64', 'asyncio.sslproto', 'pickleshare', 'IPython.core.prefilter', 'IPython.core.autocall', 'IPython.core.macro', 'IPython.core.splitinput', 'IPython.core.alias', 'IPython.core.builtin_trap', 'IPython.core.events', 'backcall', 'backcall.backcall', 'IPython.core.displayhook', 'IPython.core.displaypub', 'IPython.core.extensions', 'IPython.core.formatters', 'IPython.utils.sentinel', 'IPython.core.history', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'IPython.core.logger', 'IPython.core.payload', 'IPython.core.usage', 'IPython.display', 'IPython.lib.display', 'html', 'html.entities', 'IPython.utils.io', 'IPython.utils.capture', 'IPython.utils.strdispatch', 'IPython.core.hooks', 'IPython.utils.syspathcontext', 'IPython.utils.tempdir', 'IPython.utils.contexts', 'IPython.core.async_helpers', 'IPython.terminal.interactiveshell', 'prompt_toolkit', 'prompt_toolkit.application', 'prompt_toolkit.application.application', 'prompt_toolkit.buffer', 'prompt_toolkit.application.current', 'prompt_toolkit.eventloop', 'prompt_toolkit.eventloop.base', 'prompt_toolkit.log', 'prompt_toolkit.eventloop.coroutine', 'prompt_toolkit.eventloop.defaults', 'prompt_toolkit.utils', 'six.moves', 'wcwidth', 'wcwidth.wcwidth', 'wcwidth.table_wide', 'wcwidth.table_zero', 'prompt_toolkit.cache', 'prompt_toolkit.eventloop.future', 'prompt_toolkit.eventloop.context', 'prompt_toolkit.eventloop.async_generator', 'six.moves.queue', 'prompt_toolkit.eventloop.event', 'prompt_toolkit.application.run_in_terminal', 'prompt_toolkit.auto_suggest', 'prompt_toolkit.filters', 'prompt_toolkit.filters.base', 'prompt_toolkit.filters.app', 'prompt_toolkit.enums', 'prompt_toolkit.filters.utils', 'prompt_toolkit.filters.cli', 'prompt_toolkit.clipboard', 'prompt_toolkit.clipboard.base', 'prompt_toolkit.selection', 'prompt_toolkit.clipboard.in_memory', 'prompt_toolkit.completion', 'prompt_toolkit.completion.base', 'prompt_toolkit.completion.filesystem', 'prompt_toolkit.completion.word_completer', 'prompt_toolkit.completion.fuzzy_completer', 'prompt_toolkit.document', 'prompt_toolkit.history', 'prompt_toolkit.search', 'prompt_toolkit.key_binding', 'prompt_toolkit.key_binding.key_bindings', 'prompt_toolkit.keys', 'prompt_toolkit.key_binding.vi_state', 'prompt_toolkit.validation', 'prompt_toolkit.input', 'prompt_toolkit.input.base', 'prompt_toolkit.input.defaults', 'prompt_toolkit.input.typeahead', 'prompt_toolkit.key_binding.bindings', 'prompt_toolkit.key_binding.bindings.page_navigation', 'prompt_toolkit.key_binding.bindings.scroll', 'prompt_toolkit.key_binding.defaults', 'prompt_toolkit.key_binding.bindings.basic', 'prompt_toolkit.key_binding.key_processor', 'prompt_toolkit.key_binding.bindings.named_commands', 'prompt_toolkit.key_binding.bindings.completion', 'prompt_toolkit.key_binding.bindings.emacs', 'prompt_toolkit.key_binding.bindings.vi', 'prompt_toolkit.input.vt100_parser', 'prompt_toolkit.input.ansi_escape_sequences', 'prompt_toolkit.key_binding.digraphs', 'prompt_toolkit.key_binding.bindings.mouse', 'prompt_toolkit.layout', 'prompt_toolkit.layout.containers', 'prompt_toolkit.layout.controls', 'prompt_toolkit.formatted_text', 'prompt_toolkit.formatted_text.base', 'prompt_toolkit.formatted_text.html', 'xml', 'xml.dom', 'xml.dom.domreg', 'xml.dom.minidom', 'xml.dom.minicompat', 'xml.dom.xmlbuilder', 'xml.dom.NodeFilter', 'prompt_toolkit.formatted_text.ansi', 'prompt_toolkit.output', 'prompt_toolkit.output.base', 'prompt_toolkit.layout.screen', 'prompt_toolkit.output.defaults', 'prompt_toolkit.output.color_depth', 'prompt_toolkit.output.vt100', 'prompt_toolkit.styles', 'prompt_toolkit.styles.base', 'prompt_toolkit.styles.defaults', 'prompt_toolkit.styles.style', 'prompt_toolkit.styles.named_colors', 'prompt_toolkit.styles.pygments', 'prompt_toolkit.styles.style_transformation', 'colorsys', 'prompt_toolkit.formatted_text.pygments', 'prompt_toolkit.formatted_text.utils', 'prompt_toolkit.lexers', 'prompt_toolkit.lexers.base', 'prompt_toolkit.lexers.pygments', 'prompt_toolkit.mouse_events', 'prompt_toolkit.layout.processors', 'prompt_toolkit.layout.utils', 'prompt_toolkit.layout.dimension', 'prompt_toolkit.layout.margins', 'prompt_toolkit.layout.layout', 'prompt_toolkit.layout.menus', 'prompt_toolkit.renderer', 'prompt_toolkit.layout.mouse_handlers', 'prompt_toolkit.key_binding.bindings.cpr', 'prompt_toolkit.key_binding.emacs_state', 'prompt_toolkit.layout.dummy', 'prompt_toolkit.application.dummy', 'prompt_toolkit.shortcuts', 'prompt_toolkit.shortcuts.dialogs', 'prompt_toolkit.key_binding.bindings.focus', 'prompt_toolkit.widgets', 'prompt_toolkit.widgets.base', 'prompt_toolkit.widgets.toolbars', 'prompt_toolkit.widgets.dialogs', 'prompt_toolkit.widgets.menus', 'prompt_toolkit.shortcuts.prompt', 'prompt_toolkit.key_binding.bindings.auto_suggest', 'prompt_toolkit.key_binding.bindings.open_in_editor', 'prompt_toolkit.shortcuts.utils', 'prompt_toolkit.shortcuts.progress_bar', 'prompt_toolkit.shortcuts.progress_bar.base', 'prompt_toolkit.shortcuts.progress_bar.formatters', 'prompt_toolkit.patch_stdout', 'pygments.style', 'IPython.terminal.debugger', 'IPython.core.completer', 'unicodedata', 'IPython.core.latex_symbols', 'IPython.utils.generics', 'jedi', 'jedi.api', 'parso', 'parso.parser', 'parso.tree', 'parso._compatibility', 'parso.utils', 'parso.pgen2', 'parso.pgen2.generator', 'parso.pgen2.grammar_parser', 'parso.python', 'parso.python.tokenize', 'parso.python.token', 'parso.grammar', 'parso.python.diff', 'difflib', 'parso.python.parser', 'parso.python.tree', 'parso.python.prefix', 'parso.cache', 'gc', 'parso.python.errors', 'parso.normalizer', 'parso.python.pep8', 'jedi._compatibility', 'jedi.parser_utils', 'jedi.debug', 'jedi.settings', 'jedi.cache', 'jedi.api.classes', 'jedi.evaluate', 'jedi.evaluate.utils', 'jedi.evaluate.imports', 'jedi.evaluate.sys_path', 'jedi.evaluate.cache', 'jedi.evaluate.base_context', 'jedi.common', 'jedi.common.context', 'jedi.evaluate.helpers', 'jedi.common.utils', 'jedi.evaluate.compiled', 'jedi.evaluate.compiled.context', 'jedi.evaluate.filters', 'jedi.evaluate.flow_analysis', 'jedi.evaluate.recursion', 'jedi.evaluate.lazy_context', 'jedi.evaluate.compiled.access', 'jedi.evaluate.compiled.getattr_static', 'jedi.evaluate.compiled.fake', 'jedi.evaluate.analysis', 'jedi.evaluate.context', 'jedi.evaluate.context.module', 'jedi.evaluate.context.klass', 'jedi.evaluate.context.function', 'jedi.evaluate.docstrings', 'jedi.evaluate.pep0484', 'jedi.evaluate.arguments', 'jedi.evaluate.context.iterable', 'jedi.evaluate.param', 'jedi.evaluate.context.asynchronous', 'jedi.evaluate.parser_cache', 'jedi.evaluate.context.instance', 'jedi.evaluate.syntax_tree', 'jedi.evaluate.finder', 'jedi.api.keywords', 'pydoc_data', 'pydoc_data.topics', 'jedi.api.interpreter', 'jedi.evaluate.compiled.mixed', 'jedi.api.helpers', 'jedi.api.completion', 'jedi.api.environment', 'filecmp', 'jedi.evaluate.compiled.subprocess', 'jedi.evaluate.compiled.subprocess.functions', 'jedi.api.exceptions', 'jedi.api.project', 'jedi.evaluate.usages', 'IPython.terminal.ptutils', 'IPython.terminal.shortcuts', 'IPython.terminal.magics', 'IPython.lib.clipboard', 'IPython.terminal.pt_inputhooks', 'IPython.terminal.prompts', 'IPython.terminal.ipapp', 'IPython.core.magics', 'IPython.core.magics.auto', 'IPython.core.magics.basic', 'IPython.core.magics.code', 'urllib.request', 'email', 'http', 'http.client', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'email._parseaddr', 'calendar', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'urllib.error', 'urllib.response', 'IPython.core.magics.config', 'IPython.core.magics.display', 'IPython.core.magics.execution', 'timeit', 'cProfile', '_lsprof', 'profile', 'optparse', 'pstats', 'IPython.utils.module_paths', 'IPython.utils.timing', 'IPython.core.magics.extension', 'IPython.core.magics.history', 'IPython.core.magics.logging', 'IPython.core.magics.namespace', 'IPython.core.magics.osm', 'IPython.core.magics.packaging', 'IPython.core.magics.pylab', 'IPython.core.pylabtools', 'IPython.core.magics.script', 'IPython.lib.backgroundjobs', 'IPython.core.shellapp', 'IPython.extensions', 'IPython.extensions.storemagic', 'IPython.utils.frame', 'jupyter_client', 'jupyter_client._version', 'jupyter_client.connect', 'zmq', 'ctypes', '_ctypes', 'ctypes._endian', 'zmq.backend', 'zmq.backend.select', 'zmq.backend.cython', 'zmq.backend.cython.constants', 'cython_runtime', 'zmq.backend.cython.error', '_cython_0_29_5', 'zmq.backend.cython.message', 'zmq.error', 'zmq.backend.cython.context', 'zmq.backend.cython.socket', 'zmq.backend.cython.utils', 'zmq.backend.cython._poll', 'zmq.backend.cython._version', 'zmq.backend.cython._device', 'zmq.backend.cython._proxy_steerable', 'zmq.sugar', 'zmq.sugar.constants', 'zmq.utils', 'zmq.utils.constant_names', 'zmq.sugar.context', 'zmq.sugar.attrsettr', 'zmq.sugar.socket', 'zmq.sugar.poll', 'zmq.utils.jsonapi', 'zmq.utils.strtypes', 'simplejson', 'decimal', 'numbers', '_decimal', 'simplejson.errors', 'simplejson.raw_json', 'simplejson.decoder', 'simplejson.compat', 'simplejson.scanner', 'simplejson._speedups', 'simplejson.encoder', 'zmq.sugar.frame', 'zmq.sugar.tracker', 'zmq.sugar.version', 'zmq.sugar.stopwatch', 'jupyter_client.localinterfaces', 'jupyter_core', 'jupyter_core.version', 'jupyter_core.paths', 'distutils', 'distutils.util', 'distutils.errors', 'distutils.dep_util', 'distutils.spawn', 'distutils.debug', 'distutils.log', 'jupyter_client.launcher', 'traitlets.log', 'jupyter_client.client', 'jupyter_client.channels', 'jupyter_client.channelsabc', 'jupyter_client.clientabc', 'jupyter_client.manager', 'jupyter_client.kernelspec', 'jupyter_client.managerabc', 'jupyter_client.blocking', 'jupyter_client.blocking.client', 'jupyter_client.blocking.channels', 'jupyter_client.multikernelmanager', 'uuid', 'ctypes.util', 'ipykernel.kernelapp', 'tornado', 'tornado.ioloop', 'tornado.concurrent', 'tornado.log', 'logging.handlers', 'tornado.escape', 'tornado.util', 'tornado.speedups', 'curses', '_curses', 'tornado.stack_context', 'tornado.platform', 'tornado.platform.auto', 'tornado.platform.posix', 'tornado.platform.common', 'tornado.platform.interface', 'zmq.eventloop', 'zmq.eventloop.ioloop', 'tornado.platform.asyncio', 'tornado.gen', 'zmq.eventloop.zmqstream', 'ipykernel.iostream', 'imp', 'jupyter_client.session', 'hmac', 'jupyter_client.jsonutil', 'dateutil', 'dateutil._version', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.relativedelta', 'dateutil._common', 'dateutil.tz', 'dateutil.tz.tz', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.parser.isoparser', '_strptime', 'jupyter_client.adapter', 'ipykernel.heartbeat', 'ipykernel.ipkernel', 'IPython.utils.tokenutil', 'ipykernel.comm', 'ipykernel.comm.manager', 'ipykernel.comm.comm', 'ipykernel.kernelbase', 'tornado.queues', 'tornado.locks', 'ipykernel.jsonutil', 'ipykernel.zmqshell', 'IPython.core.payloadpage', 'ipykernel.displayhook', 'ipykernel.parentpoller', 'faulthandler', 'ipykernel.datapub', 'ipykernel.serialize', 'ipykernel.pickleutil', 'ipykernel.codeutil', 'IPython.core.completerlib', 'storemagic', 'ipywidgets', 'ipywidgets._version', 'ipywidgets.widgets', 'ipywidgets.widgets.widget', 'ipywidgets.widgets.domwidget', 'ipywidgets.widgets.trait_types', 'ipywidgets.widgets.widget_layout', 'ipywidgets.widgets.widget_style', 'ipywidgets.widgets.valuewidget', 'ipywidgets.widgets.widget_core', 'ipywidgets.widgets.widget_bool', 'ipywidgets.widgets.widget_description', 'ipywidgets.widgets.widget_button', 'ipywidgets.widgets.widget_box', 'ipywidgets.widgets.docutils', 'ipywidgets.widgets.widget_float', 'ipywidgets.widgets.widget_int', 'ipywidgets.widgets.widget_color', 'ipywidgets.widgets.widget_date', 'ipywidgets.widgets.widget_output', 'ipywidgets.widgets.widget_selection', 'ipywidgets.widgets.widget_selectioncontainer', 'ipywidgets.widgets.widget_string', 'ipywidgets.widgets.widget_controller', 'ipywidgets.widgets.interaction', 'ipywidgets.widgets.widget_link', 'ipywidgets.widgets.widget_media', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'numpy.core', 'numpy.core.info', 'numpy.core.multiarray', 'numpy.core.overrides', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'numpy.core.umath', 'numpy.core.numerictypes', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core._internal', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.shape_base', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.info', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.info', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.utils', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.mixins', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.scimath', 'numpy.lib.polynomial', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.financial', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft.info', 'numpy.fft.fftpack', 'numpy.fft.fftpack_lite', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random.mtrand', 'mtrand', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'pandas', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'pandas.compat', 'distutils.version', 'pandas.compat.chainmap', 'pandas.compat.numpy', 'pandas._libs', 'pandas._libs.tslibs', 'pandas._libs.tslibs.conversion', '_cython_0_28_2', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.strptime', 'pandas._libs.tslibs.timezones', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.frequencies', 'pandas._libs.tslibs.timestamps', 'pandas._libs.tslibs.fields', 'pandas._libs.tslibs.resolution', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.lib', 'fractions', 'pandas._libs.tslib', 'pandas.core', 'pandas.core.config_init', 'pandas.core.config', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.printing', 'pandas.core.dtypes', 'pandas.core.dtypes.inference', 'pandas.io.formats.console', 'pandas.io.formats.terminal', 'pandas.core.api', 'pandas.core.arrays', 'pandas.core.arrays.array_', 'pandas.core.dtypes.common', 'pandas._libs.algos', 'pandas.core.dtypes.dtypes', 'pandas._libs.interval', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.util', 'pandas.util._decorators', 'pandas._libs.properties', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.hashing', 'pandas.core.dtypes.cast', 'pandas.core.dtypes.missing', 'pandas.util._validators', 'pandas.core.ops', 'pandas._libs.ops', 'pandas.core.common', 'pandas.core.missing', 'pandas.core.arrays.categorical', 'pandas.core.accessor', 'pandas.core.algorithms', 'pandas.core.base', 'pandas.core.nanops', 'pandas.tseries', 'pandas.tseries.offsets', 'dateutil.easter', 'pandas.core.tools', 'pandas.core.tools.datetimes', 'pandas.core.sorting', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.interval', 'pandas.util._doctools', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.indexes.frozen', 'pandas.core.strings', 'pandas.core.arrays.period', 'pandas.core.arrays.timedeltas', 'pandas.core.arrays.integer', 'pandas.core.tools.numeric', 'pandas.core.arrays.sparse', 'pandas._libs.sparse', 'pandas.core.arrays.numpy_', 'pandas.core.groupby', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.index', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.tools.timedeltas', 'pandas.core.indexes.numeric', 'pandas.core.indexes.interval', 'pandas.util._exceptions', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.internals', 'pandas.core.internals.blocks', 'pandas._libs.internals', 'pandas.core.internals.arrays', 'pandas.core.internals.managers', 'pandas.core.internals.concat', 'pandas.io.formats.format', 'pandas.io.common', 'csv', '_csv', 'mmap', 'zipfile', 'pandas.core.internals.construction', 'pandas.core.series', 'pandas.core.indexes.accessors', 'pandas.plotting', 'pandas.plotting._misc', 'pandas.plotting._style', 'pandas.plotting._tools', 'pandas.plotting._core', 'pandas.plotting._compat', 'pandas.plotting._converter', 'matplotlib', 'matplotlib.cbook', 'gzip', 'matplotlib.cbook.deprecation', 'matplotlib.rcsetup', 'matplotlib.fontconfig_pattern', 'pyparsing', 'matplotlib.colors', 'matplotlib._color_data', 'cycler', 'matplotlib._version']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "DEBUG:matplotlib:CACHEDIR=/home/atroska/.cache/matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /home/atroska/.cache/matplotlib/fontlist-v300.json\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "from mne.time_frequency import psd_welch\n",
    "from mne.time_frequency import tfr_stockwell\n",
    "from mne import EpochsArray,create_info\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eeg1 = pd.read_csv(\"train_eeg1.csv\")\n",
    "train_eeg2 = pd.read_csv(\"train_eeg2.csv\")\n",
    "train_emg = pd.read_csv(\"train_emg.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "test_eeg1 = pd.read_csv(\"test_eeg1.csv\")\n",
    "test_eeg2 = pd.read_csv(\"test_eeg2.csv\")\n",
    "test_emg = pd.read_csv(\"test_emg.csv\")\n",
    "\n",
    "sample = pd.read_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_to_ndarray(data):\n",
    "    \"\"\"\n",
    "    Fransfer data from pd.DataFrame to ndarray for later model training\n",
    "    :param data: data in pd.DataFrame\n",
    "    :return ndarray: data in ndarray\n",
    "    \"\"\"\n",
    "    data.head()\n",
    "    ndarray = data.values\n",
    "    if ndarray.shape[1] == 2:\n",
    "        return ndarray[:, 1]\n",
    "    else:\n",
    "        return ndarray[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_eeg1_numpy=np.expand_dims(train_eeg1.to_numpy()[:,1:],-1)\n",
    "#train_eeg2_numpy=np.expand_dims(train_eeg2.to_numpy()[:,1:],-1)\n",
    "#train_emg_numpy=np.expand_dims(train_emg.to_numpy()[:,1:],-1)\n",
    "#train_labels_numpy=train_labels.to_numpy()[:,1:]\n",
    "\n",
    "#test_eeg1_numpy=np.expand_dims(test_eeg1.to_numpy()[:,1:],-1)\n",
    "#test_eeg2_numpy=np.expand_dims(test_eeg2.to_numpy()[:,1:],-1)\n",
    "#test_emg_numpy=np.expand_dims(test_emg.to_numpy()[:,1:],-1)\n",
    "\n",
    "train_eeg1_numpy=from_csv_to_ndarray(train_eeg1)\n",
    "train_eeg2_numpy=from_csv_to_ndarray(train_eeg2)\n",
    "train_emg_numpy=from_csv_to_ndarray(train_emg)\n",
    "train_labels_numpy=from_csv_to_ndarray(train_labels)\n",
    "\n",
    "test_eeg1_numpy=from_csv_to_ndarray(test_eeg1)\n",
    "test_eeg2_numpy=from_csv_to_ndarray(test_eeg1)\n",
    "test_emg_numpy=from_csv_to_ndarray(test_eeg1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_fft(signals, name, mode, cut_len):\n",
    "    print('Processing signal {} {}...'.format(mode, name))\n",
    "    if mode == 'train':\n",
    "        sub_num = 3\n",
    "    else:\n",
    "        sub_num = 2\n",
    "    fft_features = []\n",
    "    for i in range(sub_num):\n",
    "        sub_signals = signals[i*21600:(i+1)*21600]\n",
    "        sig_pad_1 = sub_signals[0, :240].copy()\n",
    "        sig_pad_2 = sub_signals[-1, -240:].copy()\n",
    "        sig_concat = sub_signals.flatten()\n",
    "        sig_concat = np.concatenate((sig_pad_1, sig_concat, sig_pad_2))\n",
    "        f, t, Sxx = signal.spectrogram(sig_concat, fs=128, window='hamming', noverlap=256 - 16, nperseg=256)\n",
    "        Sxx = Sxx[1:cut_len + 1, :]\n",
    "        for i in range(21600):\n",
    "            fft_features.append(Sxx[:, i*32:(i+1)*32])\n",
    "    fft_features = np.array(fft_features)\n",
    "    np.save('{}_{}_fft_features_new.npy'.format(mode, name), fft_features)\n",
    "    return fft_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal train eeg1...\n",
      "Processing signal train eeg2...\n",
      "Processing signal train emg...\n",
      "Processing signal test eeg1...\n",
      "Processing signal test eeg2...\n",
      "Processing signal test emg...\n"
     ]
    }
   ],
   "source": [
    "fft_train_eeg1 = extract_and_save_fft(train_eeg1_numpy, 'eeg1', 'train', 48)\n",
    "fft_train_eeg2 = extract_and_save_fft(train_eeg2_numpy, 'eeg2', 'train', 48)\n",
    "fft_train_emg = extract_and_save_fft(train_emg_numpy, 'emg', 'train', 60)\n",
    "\n",
    "fft_test_eeg1 = extract_and_save_fft(test_eeg1_numpy, 'eeg1', 'test', 48)\n",
    "fft_test_eeg2 = extract_and_save_fft(test_eeg2_numpy, 'eeg2', 'test', 48)\n",
    "fft_test_emg = extract_and_save_fft(test_emg_numpy, 'emg', 'test', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_train_eeg1 = np.log(fft_train_eeg1)\n",
    "fft_train_eeg2 = np.log(fft_train_eeg2)\n",
    "fft_train_emg = np.log(fft_train_emg)\n",
    "\n",
    "fft_test_eeg1 = np.log(fft_test_eeg1)\n",
    "fft_test_eeg2 = np.log(fft_test_eeg2)\n",
    "fft_test_emg = np.log(fft_test_emg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64800it [00:07, 8907.55it/s]\n"
     ]
    }
   ],
   "source": [
    "features_train = []\n",
    "for eeg1_sig, eeg2_sig, emg_sig in tqdm(zip(fft_train_eeg1, fft_train_eeg2, fft_train_emg)):\n",
    "    eeg1_sig = (eeg1_sig - np.mean(eeg1_sig, axis=0, keepdims=True)) / np.std(eeg1_sig, axis=0, keepdims=True)\n",
    "    eeg2_sig = (eeg2_sig - np.mean(eeg2_sig, axis=0, keepdims=True)) / np.std(eeg2_sig, axis=0, keepdims=True)\n",
    "    emg_sig = np.sum(emg_sig, axis=0, keepdims=True)\n",
    "    emg_sig = emg_sig.repeat(eeg1_sig.shape[0], axis=0)\n",
    "    eeg1_sig = eeg1_sig.reshape((eeg1_sig.shape[0], eeg1_sig.shape[1], 1))\n",
    "    eeg2_sig = eeg2_sig.reshape((eeg1_sig.shape[0], eeg1_sig.shape[1], 1))\n",
    "    emg_sig = emg_sig.reshape((eeg1_sig.shape[0], eeg1_sig.shape[1], 1))\n",
    "    features_train.append(np.concatenate((eeg1_sig, eeg2_sig, emg_sig), axis=2))\n",
    "features_train = np.array(features_train)\n",
    "np.save('fft_features_train.npy', features_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64800it [00:06, 9847.10it/s] \n"
     ]
    }
   ],
   "source": [
    "features_test = []\n",
    "for eeg1_sig, eeg2_sig, emg_sig in tqdm(zip(fft_train_eeg1, fft_train_eeg2, fft_train_emg)):\n",
    "    eeg1_sig = (eeg1_sig - np.mean(eeg1_sig, axis=0, keepdims=True)) / np.std(eeg1_sig, axis=0, keepdims=True)\n",
    "    eeg2_sig = (eeg2_sig - np.mean(eeg2_sig, axis=0, keepdims=True)) / np.std(eeg2_sig, axis=0, keepdims=True)\n",
    "    emg_sig = np.sum(emg_sig, axis=0, keepdims=True)\n",
    "    emg_sig = emg_sig.repeat(eeg1_sig.shape[0], axis=0)\n",
    "    eeg1_sig = eeg1_sig.reshape((eeg1_sig.shape[0], eeg1_sig.shape[1], 1))\n",
    "    eeg2_sig = eeg2_sig.reshape((eeg1_sig.shape[0], eeg1_sig.shape[1], 1))\n",
    "    emg_sig = emg_sig.reshape((eeg1_sig.shape[0], eeg1_sig.shape[1], 1))\n",
    "    features_test.append(np.concatenate((eeg1_sig, eeg2_sig, emg_sig), axis=2))\n",
    "features_test = np.array(features_test)\n",
    "np.save('fft_features_test.npy', features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/atroska/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/atroska/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/43/aaa740c406b1832adc6ff9d5e71c23fd2af2ebd436c42d76d85809ec8be9/torchvision-0.8.1-cp36-cp36m-manylinux1_x86_64.whl (12.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.8MB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.7.0 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/2a/58f8078744e0408619c63148f7a2e8e48cf007e4146b74d4bb67c56d161b/torch-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (776.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 776.7MB 140kB/s eta 0:00:01    22% |███████▏                        | 173.5MB 3.8MB/s eta 0:02:41    24% |███████▊                        | 186.6MB 4.1MB/s eta 0:02:25    33% |██████████▊                     | 259.1MB 5.7MB/s eta 0:01:32    37% |████████████                    | 289.0MB 6.0MB/s eta 0:01:22    49% |███████████████▉                | 385.0MB 6.9MB/s eta 0:00:58    53% |█████████████████▎              | 418.5MB 4.1MB/s eta 0:01:27    54% |█████████████████▌              | 424.2MB 6.8MB/s eta 0:00:527% |████████████████████████▊       | 601.1MB 25.2MB/s eta 0:00:07��█████▉     | 650.6MB 13.6MB/s eta 0:00:10█████▋    | 671.3MB 22.1MB/s eta 0:00:05�██████████████████    | 678.2MB 21.9MB/s eta 0:00:05��███████████████████████████▉   | 699.7MB 84.0MB/s eta 0:00:01MB/s eta 0:00:01��██████████████████▋  | 718.9MB 20.2MB/s eta 0:00:03eta 0:00:011.1MB/s eta 0:00:02████▏ | 733.3MB 85.5MB/s eta 0:00:01�█████▉ | 748.4MB 17.4MB/s eta 0:00:02████████████████▏| 755.9MB 92.8MB/s eta 0:00:01    98% |███████████████████████████████▍| 761.7MB 11.0MB/s eta 0:00:02��██████████████▋| 768.1MB 48.4MB/s eta 0:00:01████████████████▊| 769.8MB 37.5MB/s eta 0:00:01�██████████████▉| 773.7MB 88.8MB/s eta 0:00:01�██████████████▉| 774.0MB 22.8MB/s eta 0:00:01��██| 775.6MB 70.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/lib/python3/dist-packages (from torchvision) (5.1.0)\n",
      "Collecting dataclasses (from torch==1.7.0->torchvision)\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions in /home/atroska/.local/lib/python3.6/site-packages (from torch==1.7.0->torchvision) (3.7.4.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.18.2)\n",
      "Installing collected packages: dataclasses, torch, torchvision\n",
      "  Found existing installation: torch 1.6.0\n",
      "    Uninstalling torch-1.6.0:\n",
      "      Successfully uninstalled torch-1.6.0\n",
      "Successfully installed dataclasses-0.8 torch-1.7.0 torchvision-0.8.1\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x1 = x[:, :2, :, :]\n",
    "        x2 = x[:, 2, :, :]\n",
    "        x2 = torch.mean(x2, dim=(1, 2)).view(x.size(0), -1)\n",
    "        x2[x2>-0.1] = 10\n",
    "        x2[x2<-0.1] = -10\n",
    "        \"\"\"\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        # out = torch.cat((out, x2), dim=1)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SleepingDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.x = x\n",
    "        self.y = y-1\n",
    "        self.len = len(x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = torch.from_numpy(self.x[index])\n",
    "        img = img.permute((2, 0, 1))\n",
    "        return img, self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.load('fft_features_train.npy')\n",
    "y_all = train_labels_numpy\n",
    "np.save('y_all.npy', y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_classes = 3\n",
    "batch_size = 128\n",
    "learning_rate = 0.0007\n",
    "test_sub = 0\n",
    "\n",
    "x_all[:21600, :, :, 2] = (x_all[:21600, :, :, 2] - np.mean(x_all[:21600, :, :, 2])) / np.std(x_all[:21600, :, :, 2])\n",
    "x_all[21600:2*21600, :, :, 2] = (x_all[21600:2*21600, :, :, 2] - np.mean(x_all[21600:2*21600, :, :, 2])) / np.std(x_all[21600:2*21600, :, :, 2])\n",
    "x_all[:2*21600, :, :, 2] = (x_all[:2*21600, :, :, 2] - np.mean(x_all[:2*21600, :, :, 2] )) / np.std(x_all[:2*21600, :, :, 2] )\n",
    "\n",
    "if test_sub == 0:\n",
    "    x_train = x_all[21600:]\n",
    "    y_train = y_all[21600:]\n",
    "    x_test = x_all[:21600]\n",
    "    y_test = y_all[:21600]\n",
    "elif test_sub == 1:\n",
    "    x_train = np.concatenate((x_all[21600:], x_all[2*21600:]), axis=0)\n",
    "    y_train = np.concatenate((y_all[21600:], y_all[2*21600:]), axis=0)\n",
    "    x_test = x_all[21600:2*21600]\n",
    "    y_test = y_all[21600:2*21600]\n",
    "else:\n",
    "    x_train = x_all[:2*21600]\n",
    "    y_train = y_all[:2*21600]\n",
    "    x_test = x_all[2*21600:]\n",
    "    y_test = y_all[2*21600:]\n",
    "\n",
    "training_set = SleepingDataset(x_train, y_train)\n",
    "test_set = SleepingDataset(x_test, y_test)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_set, batch_size=batch_size,  shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = Net(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor([1, 1, 1]).to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n",
      "Epoch [1/5], Step [100/338], Loss: 0.3027\n",
      "Epoch [1/5], Step [200/338], Loss: 0.2211\n",
      "Epoch [1/5], Step [300/338], Loss: 0.2125\n",
      "Epoch [2/5], Step [100/338], Loss: 0.1847\n",
      "Epoch [2/5], Step [200/338], Loss: 0.2595\n",
      "Epoch [2/5], Step [300/338], Loss: 0.2788\n",
      "Epoch [3/5], Step [100/338], Loss: 0.1626\n",
      "Epoch [3/5], Step [200/338], Loss: 0.1266\n",
      "Epoch [3/5], Step [300/338], Loss: 0.2008\n",
      "Epoch [4/5], Step [100/338], Loss: 0.1381\n",
      "Epoch [4/5], Step [200/338], Loss: 0.1882\n",
      "Epoch [4/5], Step [300/338], Loss: 0.2082\n",
      "Epoch [5/5], Step [100/338], Loss: 0.1460\n",
      "Epoch [5/5], Step [200/338], Loss: 0.0885\n",
      "Epoch [5/5], Step [300/338], Loss: 0.1128\n",
      "Evaluating..\n",
      "[[10411   799    30]\n",
      " [  805  7646   202]\n",
      " [   53   189  1465]]\n",
      "0.8893668474938873\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print('Training..')\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "torch.save(model.state_dict(), './model.ckpt')\n",
    "# Test the model\n",
    "print('Evaluating..')\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "y_pred = np.zeros(len(x_test))\n",
    "y_true = np.zeros(len(x_test))\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred[cnt:cnt+len(labels)] = predicted.data.cpu().numpy()\n",
    "        y_true[cnt:cnt+len(labels)] = labels.data.cpu().numpy()\n",
    "        cnt+=len(labels)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(balanced_accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x1 = x[:, :2, :, :]\n",
    "        x2 = x[:, 2, :, :]\n",
    "        x2 = torch.mean(x2, dim=(1, 2)).view(x.size(0), -1)\n",
    "        x2[x2>-0.1] = 10\n",
    "        x2[x2<-0.1] = -10\n",
    "        \"\"\"\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        # out = torch.cat((out, x2), dim=1)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SleepingDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.x = x\n",
    "        self.y = y-1\n",
    "        self.len = len(x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = torch.from_numpy(self.x[index])\n",
    "        img = img.permute((2, 0, 1))\n",
    "        return img, self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n",
      "Epoch [1/5], Step [100/507], Loss: 0.3410\n",
      "Epoch [1/5], Step [200/507], Loss: 0.3237\n",
      "Epoch [1/5], Step [300/507], Loss: 0.3416\n",
      "Epoch [1/5], Step [400/507], Loss: 0.1464\n",
      "Epoch [1/5], Step [500/507], Loss: 0.3460\n",
      "Epoch [2/5], Step [100/507], Loss: 0.1737\n",
      "Epoch [2/5], Step [200/507], Loss: 0.3233\n",
      "Epoch [2/5], Step [300/507], Loss: 0.1774\n",
      "Epoch [2/5], Step [400/507], Loss: 0.1550\n",
      "Epoch [2/5], Step [500/507], Loss: 0.2011\n",
      "Epoch [3/5], Step [100/507], Loss: 0.2120\n",
      "Epoch [3/5], Step [200/507], Loss: 0.1902\n",
      "Epoch [3/5], Step [300/507], Loss: 0.0869\n",
      "Epoch [3/5], Step [400/507], Loss: 0.1062\n",
      "Epoch [3/5], Step [500/507], Loss: 0.1427\n",
      "Epoch [4/5], Step [100/507], Loss: 0.2174\n",
      "Epoch [4/5], Step [200/507], Loss: 0.1931\n",
      "Epoch [4/5], Step [300/507], Loss: 0.1670\n",
      "Epoch [4/5], Step [400/507], Loss: 0.2147\n",
      "Epoch [4/5], Step [500/507], Loss: 0.0868\n",
      "Epoch [5/5], Step [100/507], Loss: 0.1594\n",
      "Epoch [5/5], Step [200/507], Loss: 0.1470\n",
      "Epoch [5/5], Step [300/507], Loss: 0.1696\n",
      "Epoch [5/5], Step [400/507], Loss: 0.1614\n",
      "Epoch [5/5], Step [500/507], Loss: 0.0821\n",
      "Evaluating..\n",
      "[2. 2. 2. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('fft_features_train.npy')\n",
    "y_train = np.load('y_all.npy')\n",
    "x_test = np.load('fft_features_test.npy')\n",
    "\n",
    "num_epochs = 5\n",
    "num_classes = 3\n",
    "batch_size = 128\n",
    "learning_rate = 0.0007\n",
    "\n",
    "training_set = SleepingDataset(x_train, y_train)\n",
    "test_set = SleepingDataset(x_test, np.zeros(len(x_test)))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_set, batch_size=batch_size,  shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = Net(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "print('Training..')\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "torch.save(model.state_dict(), './model.ckpt')\n",
    "# Test the model\n",
    "print('Evaluating..')\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "y_pred = np.zeros(len(x_test))\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred[cnt:cnt+len(labels)] = predicted.data.cpu().numpy()\n",
    "        cnt+=len(labels)\n",
    "print(y_pred)\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = np.arange(len(y_pred))\n",
    "sub['y'] = y_pred+1\n",
    "y_pred_save_dir = 'y_test_5.0.csv'\n",
    "sub.to_csv(y_pred_save_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
